{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142cde2a-fe33-4a81-92bb-d093356cc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install awkward pyarrow matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338571d9",
   "metadata": {},
   "source": [
    "### Load the data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42afe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ak.from_parquet('particles.parquet')\n",
    "pt, eta, phi, met_ref = f.pt, f.eta, f.phi, f.met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f21bef",
   "metadata": {},
   "source": [
    "### Reference MET implementation\n",
    "\n",
    "This implementation is as simple as can be:\n",
    "- run over all events at once\n",
    "- split the particle momentum into x & y components\n",
    "- sum the px and py for the particles in each event\n",
    "- compute the vector magnitude from the MET x & y components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_met(pt : ak.Array,\n",
    "                phi : ak.Array):\n",
    "    # compute the x and y components of each particle's pT\n",
    "    px = pt * np.cos(phi)\n",
    "    py = pt * np.sin(phi)\n",
    "    # sum over the particles to calculate the MET vector (px, py)\n",
    "    met_x = np.sum(px, axis=1)\n",
    "    met_y = np.sum(py, axis=1)\n",
    "    # compute the magnitude of the MET vector\n",
    "    met = np.sqrt(met_x**2 + met_y**2)\n",
    "    return met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8036801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the MET reference\n",
    "met_ref = compute_met(pt, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e139b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MET computation from HLS testbench\n",
    "# a dummy file of zeros is provided, run this again with your real results!\n",
    "met_hls = np.genfromtxt('met_hls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d586d91",
   "metadata": {},
   "source": [
    "### Plot MET distribution\n",
    "\n",
    "You can overlay your results onto this as another plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_spectrum = np.linspace(0, 1000, 101)\n",
    "hist_ref, _ = np.histogram(met_ref, bins=bins_spectrum)\n",
    "hist_hls, _ = np.histogram(met_hls, bins=bins_spectrum)\n",
    "plt.step(bins_spectrum[:-1], hist_ref, label='MET Python Reference')\n",
    "plt.step(bins_spectrum[:-1], hist_hls, label='MET HLS Implementation')\n",
    "plt.semilogy()\n",
    "plt.legend()\n",
    "plt.xlabel('MET [GeV]')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('met_distribution.png')\n",
    "plt.savefig('met_distribution.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af098d",
   "metadata": {},
   "source": [
    "### Plot MET Residual\n",
    "\n",
    "Plot the residual between the MET reference and yours. A dummy file is provided where the MET is always 0, yours should look much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da953e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_residual = met_ref - met_hls\n",
    "max_residual = np.max(np.abs(met_residual))\n",
    "bins_residual = np.linspace(-max_residual, max_residual, 101)\n",
    "hist_residual, _ = np.histogram(met_residual, bins_residual)\n",
    "\n",
    "plt.step(bins_residual[:-1], hist_residual, label='Example MET')\n",
    "#plt.semilogy()\n",
    "plt.legend()\n",
    "plt.xlabel('Î”MET(Python, HLS) [GeV]')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('met_residual.png')\n",
    "plt.savefig('met_residual.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048855c2",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "You can use this tolerance test to check whether your implementation is viable. The targets are:\n",
    "- absolute MET never more than 10 GeV different than the reference\n",
    "- relative MET never more than 2% different than the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    np.testing.assert_allclose(met_hls, met_ref, rtol=0.02, atol=10)\n",
    "    print(\"All Close\")\n",
    "except AssertionError as AE:\n",
    "    print(AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8d8df",
   "metadata": {},
   "source": [
    "### More tools\n",
    "\n",
    "This exercise is all about choosing the right precision for your variables. You want to minimise the resources and latency without compromising the MET precision. Below are some visualizations that will help you to choose the right precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "bins_pt = np.linspace(0, ak.max(pt)*1.1, 101)\n",
    "hist_pt, _ = np.histogram(ak.ravel(pt), bins=bins_pt)\n",
    "axs[0].step(bins_pt[:-1], hist_pt)\n",
    "axs[0].semilogy()\n",
    "axs[0].set_xlabel(\"$p_T$ [GeV]\")\n",
    "axs[0].set_ylabel(\"Count\")\n",
    "\n",
    "bins_phi = np.linspace(-np.pi, np.pi, 101)\n",
    "hist_phi, _ = np.histogram(ak.ravel(phi), bins=bins_phi)\n",
    "axs[1].step(bins_phi[:-1], hist_phi)\n",
    "#axs[0].semilogy()\n",
    "axs[1].set_xlabel(\"$\\phi$\")\n",
    "axs[1].set_ylabel(\"Count\")\n",
    "axs[1].set_ylim((0, np.max(hist_phi)*1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = pt * np.cos(phi)\n",
    "py = pt * np.sin(phi)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.hexbin(ak.ravel(px), ak.ravel(py), gridsize=50, cmap='viridis', norm=matplotlib.colors.LogNorm())\n",
    "plt.xlabel(\"$p_x$ [GeV]\")\n",
    "plt.ylabel(\"$p_y$ [GeV]\")\n",
    "plt.title(\"Phase Space of $p_x$ vs $p_y$\")\n",
    "plt.colorbar(label=\"Event count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out quantizing different parts of the computation in Python before HLS\n",
    "# You can use this to help think about the fractional part\n",
    "# e.g. here we quantize the pt and phi\n",
    "# consider that the full computation also include quantizing the computations in the compute_met function\n",
    "pt_q = ak.round(pt / 2**-1) * 2**-1\n",
    "phi_q = ak.round(phi / 2**-4) * 2**-4\n",
    "\n",
    "met_q = compute_met(pt_q, phi_q)\n",
    "\n",
    "print(f\"Quantized MET: {met_q[0]:.2f} GeV\")\n",
    "print(f\"Reference MET: {met_ref[0]:.2f} GeV\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
